{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22825b28-dc46-4edc-9435-5799e43c7e35",
   "metadata": {},
   "source": [
    "This notebook includes the modified version of Langchain's Diffbot Graph Transformer.\n",
    "Please refer to the original full document: \n",
    "https://api.python.langchain.com/en/latest/graph_transformers/langchain_experimental.graph_transformers.diffbot.DiffbotGraphTransformer.html\n",
    "\n",
    "https://api.python.langchain.com/en/latest/_modules/langchain_experimental/graph_transformers/diffbot.html#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc740982-729a-4647-ae00-f985b6c92cf9",
   "metadata": {},
   "source": [
    "# Customize \"GraphDocument\" for DiffbotTransformer library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a886f-0ba9-4d31-b890-4d1cfbf85922",
   "metadata": {},
   "source": [
    "Original source:\n",
    "https://api.python.langchain.com/en/latest/_modules/langchain_community/graphs/graph_document.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eabaf0f-ce44-4a60-9f87-14423064299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Sequence, Tuple, Union\n",
    "from langchain_core.load.serializable import Serializable\n",
    "from langchain_core.pydantic_v1 import Field\n",
    "\n",
    "class Node(Serializable):\n",
    "    \"\"\"Represents a node in a graph with associated properties.\n",
    "\n",
    "    Attributes:\n",
    "        id (Union[str, int]): A unique identifier for the node.\n",
    "        type (str): The type or label of the node, default is \"Node\".\n",
    "        properties (dict): Additional properties and metadata associated with the node.\n",
    "    \"\"\"\n",
    "\n",
    "    id: Union[str, int]\n",
    "    type: str = \"Node\"\n",
    "    properties: dict = Field(default_factory=dict)\n",
    "\n",
    "class Relationship(Serializable):\n",
    "    \"\"\"Represents a directed relationship between two nodes in a graph.\n",
    "\n",
    "    Attributes:\n",
    "        source (Node): The source node of the relationship.\n",
    "        target (Node): The target node of the relationship.\n",
    "        type (str): The type of the relationship.\n",
    "        properties (dict): Additional properties associated with the relationship.\n",
    "    \"\"\"\n",
    "\n",
    "    source: Node\n",
    "    target: Node\n",
    "    type: str\n",
    "    properties: dict = Field(default_factory=dict)\n",
    "\n",
    "class GraphDocument(Serializable):\n",
    "    \"\"\"Represents a graph document consisting of nodes and relationships.\n",
    "\n",
    "    Attributes:\n",
    "        nodes (List[Node]): A list of nodes in the graph.\n",
    "        relationships (List[Relationship]): A list of relationships in the graph.\n",
    "    \"\"\"\n",
    "\n",
    "    nodes: List[Node]\n",
    "    relationships: List[Relationship]\n",
    "\n",
    "import requests\n",
    "from langchain.schema import Document\n",
    "from langchain.utils import get_from_env\n",
    "from langchain_community.graphs.graph_document import Node, Relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1604f94-14cc-4c13-8e7d-c9440a00eec5",
   "metadata": {},
   "source": [
    "# Customize \"process_response\" under class DiffbotGraphTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9c2e54-cada-4ae1-93f2-89466b9e936a",
   "metadata": {},
   "source": [
    "Original source: https://api.python.langchain.com/en/latest/graph_transformers/langchain_experimental.graph_transformers.diffbot.DiffbotGraphTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84048eb1-59b2-4f3f-9f00-581e5d83ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_property_key(s: str) -> str:\n",
    "    words = s.split()\n",
    "    if not words:\n",
    "        return s\n",
    "    first_word = words[0].lower()\n",
    "    capitalized_words = [word.capitalize() for word in words[1:]]\n",
    "    return \"\".join([first_word] + capitalized_words)\n",
    "\n",
    "class NodesList:\n",
    "    \"\"\"\n",
    "    Manages a list of nodes with associated properties.\n",
    "\n",
    "    Attributes:\n",
    "        nodes (Dict[Tuple, Any]): Stores nodes as keys and their properties as values.\n",
    "            Each key is a tuple where the first element is the\n",
    "            node ID and the second is the node type.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self.nodes: Dict[Tuple[Union[str, int], str], Any] = dict()\n",
    "\n",
    "\n",
    "    def add_node_property(\n",
    "        self, node: Tuple[Union[str, int], str], properties: Dict[str, Any]\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Adds or updates node properties.\n",
    "\n",
    "        If the node does not exist in the list, it's added along with its properties.\n",
    "        If the node already exists, its properties are updated with the new values.\n",
    "\n",
    "        Args:\n",
    "            node (Tuple): A tuple containing the node ID and node type.\n",
    "            properties (Dict): A dictionary of properties to add or update for the node.\n",
    "        \"\"\"\n",
    "        if node not in self.nodes:\n",
    "            self.nodes[node] = properties\n",
    "        else:\n",
    "            self.nodes[node].update(properties)\n",
    "\n",
    "\n",
    "    def return_node_list(self) -> List[Node]:\n",
    "        \"\"\"\n",
    "        Returns the nodes as a list of Node objects.\n",
    "\n",
    "        Each Node object will have its ID, type, and properties populated.\n",
    "\n",
    "        Returns:\n",
    "            List[Node]: A list of Node objects.\n",
    "        \"\"\"\n",
    "        nodes = [\n",
    "            Node(id=key[0], type=key[1], properties=self.nodes[key])\n",
    "            for key in self.nodes\n",
    "        ]\n",
    "        return nodes\n",
    "\n",
    "\n",
    "\n",
    "# Properties that should be treated as node properties instead of relationships\n",
    "FACT_TO_PROPERTY_TYPE = [\n",
    "    \"Date\",\n",
    "    \"Number\",\n",
    "    \"Job title\",\n",
    "    \"Cause of death\",\n",
    "    \"Organization type\",\n",
    "    \"Academic title\",\n",
    "]\n",
    "\n",
    "\n",
    "schema_mapping = [\n",
    "    (\"HEADQUARTERS\", \"ORGANIZATION_LOCATIONS\"),\n",
    "    (\"RESIDENCE\", \"PERSON_LOCATION\"),\n",
    "    (\"ALL_PERSON_LOCATIONS\", \"PERSON_LOCATION\"),\n",
    "    (\"CHILD\", \"HAS_CHILD\"),\n",
    "    (\"PARENT\", \"HAS_PARENT\"),\n",
    "    (\"CUSTOMERS\", \"HAS_CUSTOMER\"),\n",
    "    (\"SKILLED_AT\", \"INTERESTED_IN\"),\n",
    "]\n",
    "\n",
    "\n",
    "class SimplifiedSchema:\n",
    "    \"\"\"\n",
    "    Provides functionality for working with a simplified schema mapping.\n",
    "\n",
    "    Attributes:\n",
    "        schema (Dict): A dictionary containing the mapping to simplified schema types.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initializes the schema dictionary based on the predefined list.\"\"\"\n",
    "        self.schema = dict()\n",
    "        for row in schema_mapping:\n",
    "            self.schema[row[0]] = row[1]\n",
    "\n",
    "\n",
    "    def get_type(self, type: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieves the simplified schema type for a given original type.\n",
    "\n",
    "        Args:\n",
    "            type (str): The original schema type to find the simplified type for.\n",
    "\n",
    "        Returns:\n",
    "            str: The simplified schema type if it exists;\n",
    "                 otherwise, returns the original type.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.schema[type]\n",
    "        except KeyError:\n",
    "            return type\n",
    "\n",
    "\n",
    "class DiffbotGraphTransformer:\n",
    "    \"\"\"Transforms documents into graph documents using Diffbot's NLP API.\n",
    "\n",
    "    A graph document transformation system takes a sequence of Documents and returns a\n",
    "    sequence of Graph Documents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        diffbot_api_key: Optional[str] = None,\n",
    "        fact_confidence_threshold: float = 0.7,\n",
    "        include_qualifiers: bool = True,\n",
    "        include_evidence: bool = True,\n",
    "        simplified_schema: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the graph transformer with various options.\n",
    "\n",
    "        Args:\n",
    "            diffbot_api_key (str):\n",
    "               The API key for Diffbot's NLP services.\n",
    "\n",
    "            fact_confidence_threshold (float):\n",
    "                Minimum confidence level for facts to be included.\n",
    "            include_qualifiers (bool):\n",
    "                Whether to include qualifiers in the relationships.\n",
    "            include_evidence (bool):\n",
    "                Whether to include evidence for the relationships.\n",
    "            simplified_schema (bool):\n",
    "                Whether to use a simplified schema for relationships.\n",
    "        \"\"\"\n",
    "        self.diffbot_api_key = diffbot_api_key or get_from_env(\n",
    "            \"diffbot_api_key\", \"DIFFBOT_API_KEY\"\n",
    "        )\n",
    "        self.fact_threshold_confidence = fact_confidence_threshold\n",
    "        self.include_qualifiers = include_qualifiers\n",
    "        self.include_evidence = include_evidence\n",
    "        self.simplified_schema = None\n",
    "        if simplified_schema:\n",
    "            self.simplified_schema = SimplifiedSchema()\n",
    "\n",
    "\n",
    "    def nlp_request(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Make an API request to the Diffbot NLP endpoint.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be processed.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: The JSON response from the API.\n",
    "        \"\"\"\n",
    "\n",
    "        # Relationship extraction only works for English\n",
    "        payload = {\n",
    "            \"content\": text,\n",
    "            \"lang\": \"en\",\n",
    "        }\n",
    "\n",
    "        FIELDS = \"facts\"\n",
    "        HOST = \"nl.diffbot.com\"\n",
    "        url = (\n",
    "            f\"https://{HOST}/v1/?fields={FIELDS}&\"\n",
    "            f\"token={self.diffbot_api_key}&language=en\"\n",
    "        )\n",
    "        result = requests.post(url, data=payload)\n",
    "        return result.json()\n",
    "\n",
    "    def process_response(\n",
    "        self, payload: Dict[str, Any]):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                payload (Dict[str, Any]): The JSON response from Diffbot's NLP API.\n",
    "    \n",
    "            Returns:\n",
    "                GraphDocument: The transformed document as a graph.\n",
    "            \"\"\"\n",
    "    \n",
    "            # Return empty result if there are no facts\n",
    "            if \"facts\" not in payload or not payload[\"facts\"]:\n",
    "                return GraphDocument(nodes=[], relationships=[])\n",
    "    \n",
    "            # Nodes are a custom class because we need to deduplicate\n",
    "            nodes_list = NodesList()\n",
    "            # Relationships are a list because we don't deduplicate nor anything else\n",
    "            relationships = list()\n",
    "            for record in payload[\"facts\"]:\n",
    "                # Skip if the fact is below the threshold confidence\n",
    "                if record[\"confidence\"] < self.fact_threshold_confidence:\n",
    "                    continue\n",
    "    \n",
    "                # TODO: It should probably be treated as a node property\n",
    "                if not record[\"value\"][\"allTypes\"]:\n",
    "                    continue\n",
    "    \n",
    "                # Define source node\n",
    "                source_id = (\n",
    "                    record[\"entity\"][\"allUris\"][0]\n",
    "                    if record[\"entity\"][\"allUris\"]\n",
    "                    else record[\"entity\"][\"name\"]\n",
    "                )\n",
    "                source_label = record[\"entity\"][\"allTypes\"][0][\"name\"].capitalize()\n",
    "                source_name = record[\"entity\"][\"name\"]\n",
    "                source_node = Node(id=source_id, type=source_label)\n",
    "                nodes_list.add_node_property(\n",
    "                    (source_id, source_label), {\"name\": source_name}\n",
    "                )\n",
    "    \n",
    "                # Define target node\n",
    "                target_id = (\n",
    "                    record[\"value\"][\"allUris\"][0]\n",
    "                    if record[\"value\"][\"allUris\"]\n",
    "                    else record[\"value\"][\"name\"]\n",
    "                )\n",
    "                target_label = record[\"value\"][\"allTypes\"][0][\"name\"].capitalize()\n",
    "                target_name = record[\"value\"][\"name\"]\n",
    "                # Some facts are better suited as node properties\n",
    "                if target_label in FACT_TO_PROPERTY_TYPE:\n",
    "                    nodes_list.add_node_property(\n",
    "                        (source_id, source_label),\n",
    "                        {format_property_key(record[\"property\"][\"name\"]): target_name},\n",
    "                    )\n",
    "                else:  # Define relationship\n",
    "                    # Define target node object\n",
    "                    target_node = Node(id=target_id, type=target_label)\n",
    "                    nodes_list.add_node_property(\n",
    "                        (target_id, target_label), {\"name\": target_name}\n",
    "                    )\n",
    "                    # Define relationship type\n",
    "                    rel_type = record[\"property\"][\"name\"].replace(\" \", \"_\").upper()\n",
    "                    if self.simplified_schema:\n",
    "                        rel_type = self.simplified_schema.get_type(rel_type)\n",
    "    \n",
    "                    # Relationship qualifiers/properties\n",
    "                    rel_properties = dict()\n",
    "                    relationship_evidence = [el[\"passage\"] for el in record[\"evidence\"]][0]\n",
    "                    if self.include_evidence:\n",
    "                        rel_properties.update({\"evidence\": relationship_evidence})\n",
    "                    if self.include_qualifiers and record.get(\"qualifiers\"):\n",
    "                        for property in record[\"qualifiers\"]:\n",
    "                            prop_key = format_property_key(property[\"property\"][\"name\"])\n",
    "                            rel_properties[prop_key] = property[\"value\"][\"name\"]\n",
    "    \n",
    "                    relationship = Relationship(\n",
    "                        source=source_node,\n",
    "                        target=target_node,\n",
    "                        type=rel_type,\n",
    "                        properties=rel_properties,\n",
    "                    )\n",
    "                    relationships.append(relationship)\n",
    "    \n",
    "            return GraphDocument(\n",
    "                nodes=nodes_list.return_node_list(),\n",
    "                relationships=relationships,\n",
    "            )\n",
    "    # Not being used in this project \n",
    "    def convert_to_graph_documents(\n",
    "        self, documents: Sequence[Document]\n",
    "    ) -> List[GraphDocument]:\n",
    "        \"\"\"Convert a sequence of documents into graph documents.\n",
    "\n",
    "        Args:\n",
    "            documents (Sequence[Document]): The original documents.\n",
    "            **kwargs: Additional keyword arguments.\n",
    "\n",
    "        Returns:\n",
    "            Sequence[GraphDocument]: The transformed documents as graphs.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for document in documents:\n",
    "            raw_results = self.nlp_request(document.page_content)\n",
    "            graph_document = self.process_response(raw_results, document)\n",
    "            results.append(graph_document)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84094b-c177-4a01-a167-ee63d00ef2b9",
   "metadata": {},
   "source": [
    "# Modify \"add_graph_documet\" -> \"add_graph_from_text\" under neo4j_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30dbd2-2d3d-42a2-9cb0-75821b8102a3",
   "metadata": {},
   "source": [
    "Original source: https://api.python.langchain.com/en/latest/_modules/langchain_community/graphs/neo4j_graph.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a6e01-6130-46e1-a5bf-6c93d7bca9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from langchain_core.utils import get_from_env\n",
    "\n",
    "from langchain_community.graphs.graph_store import GraphStore\n",
    "\n",
    "node_properties_query = \"\"\"\n",
    "CALL apoc.meta.data()\n",
    "YIELD label, other, elementType, type, property\n",
    "WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
    "WITH label AS nodeLabels, collect({property:property, type:type}) AS properties\n",
    "RETURN {labels: nodeLabels, properties: properties} AS output\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "rel_properties_query = \"\"\"\n",
    "CALL apoc.meta.data()\n",
    "YIELD label, other, elementType, type, property\n",
    "WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"relationship\"\n",
    "WITH label AS nodeLabels, collect({property:property, type:type}) AS properties\n",
    "RETURN {type: nodeLabels, properties: properties} AS output\n",
    "\"\"\"\n",
    "\n",
    "rel_query = \"\"\"\n",
    "CALL apoc.meta.data()\n",
    "YIELD label, other, elementType, type, property\n",
    "WHERE type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
    "UNWIND other AS other_node\n",
    "RETURN {start: label, type: property, end: toString(other_node)} AS output\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def value_sanitize(d: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Sanitizes the input dictionary by removing embedding-like values,\n",
    "    lists with more than 128 elements, that are mostly irrelevant for\n",
    "    generating answers in a LLM context. These properties, if left in\n",
    "    results, can occupy significant context space and detract from\n",
    "    the LLM's performance by introducing unnecessary noise and cost.\n",
    "    \"\"\"\n",
    "    LIST_LIMIT = 128\n",
    "    # Create a new dictionary to avoid changing size during iteration\n",
    "    new_dict = {}\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            # Recurse to handle nested dictionaries\n",
    "            new_dict[key] = value_sanitize(value)\n",
    "        elif isinstance(value, list):\n",
    "            # check if it has less than LIST_LIMIT values\n",
    "            if len(value) < LIST_LIMIT:\n",
    "                # if value is a list, check if it contains dictionaries to clean\n",
    "                cleaned_list = []\n",
    "                for item in value:\n",
    "                    if isinstance(item, dict):\n",
    "                        cleaned_list.append(value_sanitize(item))\n",
    "                    else:\n",
    "                        cleaned_list.append(item)\n",
    "                new_dict[key] = cleaned_list\n",
    "        else:\n",
    "            new_dict[key] = value\n",
    "    return new_dict\n",
    "\n",
    "class Neo4jGraph(GraphStore):\n",
    "    \"\"\"Provides a connection to a Neo4j database for various graph operations.\n",
    "    Parameters:\n",
    "    url (Optional[str]): The URL of the Neo4j database server.\n",
    "    username (Optional[str]): The username for database authentication.\n",
    "    password (Optional[str]): The password for database authentication.\n",
    "    database (str): The name of the database to connect to. Default is 'neo4j'.\n",
    "    timeout (Optional[float]): The timeout for transactions in seconds.\n",
    "            Useful for terminating long-running queries.\n",
    "            By default, there is no timeout set.\n",
    "    sanitize (bool): A flag to indicate whether to remove lists with\n",
    "            more than 128 elements from results. Useful for removing\n",
    "            embedding-like properties from database responses. Default is False.\n",
    "\n",
    "    *Security note*: Make sure that the database connection uses credentials\n",
    "        that are narrowly-scoped to only include necessary permissions.\n",
    "        Failure to do so may result in data corruption or loss, since the calling\n",
    "        code may attempt commands that would result in deletion, mutation\n",
    "        of data if appropriately prompted or reading sensitive data if such\n",
    "        data is present in the database.\n",
    "        The best way to guard against such negative outcomes is to (as appropriate)\n",
    "        limit the permissions granted to the credentials used with this tool.\n",
    "\n",
    "        See https://python.langchain.com/docs/security for more information.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        url: Optional[str] = None,\n",
    "        username: Optional[str] = None,\n",
    "        password: Optional[str] = None,\n",
    "        database: str = \"neo4j\",\n",
    "        timeout: Optional[float] = None,\n",
    "        sanitize: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"Create a new Neo4j graph wrapper instance.\"\"\"\n",
    "        try:\n",
    "            import neo4j\n",
    "        except ImportError:\n",
    "            raise ValueError(\n",
    "                \"Could not import neo4j python package. \"\n",
    "                \"Please install it with `pip install neo4j`.\"\n",
    "            )\n",
    "\n",
    "        url = get_from_env(\"url\", \"NEO4J_URI\", url)\n",
    "        username = get_from_env(\"username\", \"NEO4J_USERNAME\", username)\n",
    "        password = get_from_env(\"password\", \"NEO4J_PASSWORD\", password)\n",
    "        database = get_from_env(\"database\", \"NEO4J_DATABASE\", database)\n",
    "\n",
    "        self._driver = neo4j.GraphDatabase.driver(url, auth=(username, password))\n",
    "        self._database = database\n",
    "        self.timeout = timeout\n",
    "        self.sanitize = sanitize\n",
    "        self.schema: str = \"\"\n",
    "        self.structured_schema: Dict[str, Any] = {}\n",
    "        # Verify connection\n",
    "        try:\n",
    "            self._driver.verify_connectivity()\n",
    "        except neo4j.exceptions.ServiceUnavailable:\n",
    "            raise ValueError(\n",
    "                \"Could not connect to Neo4j database. \"\n",
    "                \"Please ensure that the url is correct\"\n",
    "            )\n",
    "        except neo4j.exceptions.AuthError:\n",
    "            raise ValueError(\n",
    "                \"Could not connect to Neo4j database. \"\n",
    "                \"Please ensure that the username and password are correct\"\n",
    "            )\n",
    "        # Set schema\n",
    "        try:\n",
    "            self.refresh_schema()\n",
    "        except neo4j.exceptions.ClientError:\n",
    "            raise ValueError(\n",
    "                \"Could not use APOC procedures. \"\n",
    "                \"Please ensure the APOC plugin is installed in Neo4j and that \"\n",
    "                \"'apoc.meta.data()' is allowed in Neo4j configuration \"\n",
    "            )\n",
    "\n",
    "\n",
    "    @property\n",
    "    def get_schema(self) -> str:\n",
    "        \"\"\"Returns the schema of the Graph\"\"\"\n",
    "        return self.schema\n",
    "\n",
    "    @property\n",
    "    def get_structured_schema(self) -> Dict[str, Any]:\n",
    "        \"\"\"Returns the structured schema of the Graph\"\"\"\n",
    "        return self.structured_schema\n",
    "\n",
    "    def query(self, query: str, params: dict = {}) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Query Neo4j database.\"\"\"\n",
    "        from neo4j import Query\n",
    "        from neo4j.exceptions import CypherSyntaxError\n",
    "\n",
    "        with self._driver.session(database=self._database) as session:\n",
    "            try:\n",
    "                data = session.run(Query(text=query, timeout=self.timeout), params)\n",
    "                json_data = [r.data() for r in data]\n",
    "                if self.sanitize:\n",
    "                    json_data = [value_sanitize(el) for el in json_data]\n",
    "                return json_data\n",
    "            except CypherSyntaxError as e:\n",
    "                raise ValueError(f\"Generated Cypher Statement is not valid\\n{e}\")\n",
    "\n",
    "\n",
    "    def refresh_schema(self) -> None:\n",
    "        \"\"\"\n",
    "        Refreshes the Neo4j graph schema information.\n",
    "        \"\"\"\n",
    "        node_properties = [el[\"output\"] for el in self.query(node_properties_query)]\n",
    "        rel_properties = [el[\"output\"] for el in self.query(rel_properties_query)]\n",
    "        relationships = [el[\"output\"] for el in self.query(rel_query)]\n",
    "\n",
    "        self.structured_schema = {\n",
    "            \"node_props\": {el[\"labels\"]: el[\"properties\"] for el in node_properties},\n",
    "            \"rel_props\": {el[\"type\"]: el[\"properties\"] for el in rel_properties},\n",
    "            \"relationships\": relationships,\n",
    "        }\n",
    "\n",
    "        # Format node properties\n",
    "        formatted_node_props = []\n",
    "        for el in node_properties:\n",
    "            props_str = \", \".join(\n",
    "                [f\"{prop['property']}: {prop['type']}\" for prop in el[\"properties\"]]\n",
    "            )\n",
    "            formatted_node_props.append(f\"{el['labels']} {{{props_str}}}\")\n",
    "\n",
    "        # Format relationship properties\n",
    "        formatted_rel_props = []\n",
    "        for el in rel_properties:\n",
    "            props_str = \", \".join(\n",
    "                [f\"{prop['property']}: {prop['type']}\" for prop in el[\"properties\"]]\n",
    "            )\n",
    "            formatted_rel_props.append(f\"{el['type']} {{{props_str}}}\")\n",
    "\n",
    "        # Format relationships\n",
    "        formatted_rels = [\n",
    "            f\"(:{el['start']})-[:{el['type']}]->(:{el['end']})\" for el in relationships\n",
    "        ]\n",
    "\n",
    "        self.schema = \"\\n\".join(\n",
    "            [\n",
    "                \"Node properties are the following:\",\n",
    "                \",\".join(formatted_node_props),\n",
    "                \"Relationship properties are the following:\",\n",
    "                \",\".join(formatted_rel_props),\n",
    "                \"The relationships are the following:\",\n",
    "                \",\".join(formatted_rels),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def add_graph_from_txt(\n",
    "        self, graph_document: GraphDocument\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Take GraphDocument as input as uses it to construct a graph.\n",
    "        \"\"\"\n",
    "        # Import nodes\n",
    "        self.query(\n",
    "            (\n",
    "                \"UNWIND $data AS row \"\n",
    "                \"CALL apoc.merge.node([row.type], {id: row.id}, \"\n",
    "                \"row.properties, {}) YIELD node \"\n",
    "                \"RETURN distinct 'done' AS result\"\n",
    "            ),\n",
    "            {\n",
    "                \"data\": [el.__dict__ for el in graph_document.nodes],\n",
    "            },\n",
    "        )\n",
    "        # Import relationships\n",
    "        self.query(\n",
    "            \"UNWIND $data AS row \"\n",
    "            \"CALL apoc.merge.node([row.source_label], {id: row.source},\"\n",
    "            \"{}, {}) YIELD node as source \"\n",
    "            \"CALL apoc.merge.node([row.target_label], {id: row.target},\"\n",
    "            \"{}, {}) YIELD node as target \"\n",
    "            \"CALL apoc.merge.relationship(source, row.type, \"\n",
    "            \"{}, row.properties, target) YIELD rel \"\n",
    "            \"RETURN distinct 'done'\",\n",
    "            {\n",
    "                \"data\": [\n",
    "                    {\n",
    "                        \"source\": el.source.id,\n",
    "                        \"source_label\": el.source.type,\n",
    "                        \"target\": el.target.id,\n",
    "                        \"target_label\": el.target.type,\n",
    "                        \"type\": el.type.replace(\" \", \"_\").upper(),\n",
    "                        \"properties\": el.properties,\n",
    "                    }\n",
    "                    for el in graph_document.relationships\n",
    "                ]\n",
    "            },\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
